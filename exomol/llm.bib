% Encoding: UTF-8
@article{25MaVeJo.llm,
author = {Maharana PR, Verma A and Joshi K.},
title = {{Retrieval augmented generation for building datasets from scientific literature}},
journal = ChemRxiv,
year = {2025},
abstract = {In this work, we show that employing Retrieval Augmented Generation (RAG) with a 
Large Language Model (LLM) enables us to extract accurate data from scientific literature and 
construct datasets. The rapid growth in publications necessitates the automation of extraction 
of structured data as it is crucial for training machine learning (ML) models. The pipeline 
developed is simple and can be adjusted accordingly with natural language as input. 
Quantization enables us to run LLMs on consumer hardware and remove the reliance on 
closed-source models. Both Llama3-8B and Gemma2-9B with RAG give structured output 
consistently and with high accuracy as compared to direct prompting. Using the newly developed 
protocol, we created a data set of metal hydrides for solid-state hydrogen storage from paper 
abstracts. The accuracy of the generated dataset was > 88 \% in the cases tested. Further, we 
demonstrate that the generated dataset is ready-to-use for ML models by testing it with HYST 
to predict the H2wt\% at a given temperature. Thus, we demonstrate a pipeline to create 
datasets from scientific literature at minimal computational cost and high accuracy.
}
DOI = {10.26434/chemrxiv-2024-qjx32-v2},
note = {This content is a preprint and has not been peer-reviewed.},
}

@article{24PoMo.llm,
author={Polak, Maciej P. and Morgan, Dane},
title={Extracting accurate materials data from research papers with conversational language models and prompt engineering},
journal={Nature Communications},
year={2024},
month={Feb},
volume={15},
number={1},
pages={1569},
abstract={There has been a growing effort to replace manual extraction of data from research papers with automated data extraction based on natural language processing, language models, and recently, large language models (LLMs). Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding. In this work, we propose the ChatExtract method that can fully automate very accurate data extraction with minimal initial effort and background, using an advanced conversational LLM. ChatExtract consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract that data, and assure the data's correctness through a series of follow-up questions. These follow-up questions largely overcome known issues with LLMs providing factually inaccurate responses. ChatExtract can be applied with any conversational LLMs and yields very high quality data extraction. In tests on materials data, we find precision and recall both close to 90{\%} from the best conversational LLMs, like GPT-4. We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts. These results suggest that approaches similar to ChatExtract, due to their simplicity, transferability, and accuracy are likely to become powerful tools for data extraction in the near future. Finally, databases for critical cooling rates of metallic glasses and yield strengths of high entropy alloys are developed using ChatExtract.},
issn={2041-1723},
doi={10.1038/s41467-024-45914-8},
}


